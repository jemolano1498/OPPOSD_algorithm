{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from RunningEnv import RunningEnv\n",
    "from RunningEnv import EnvWrapper\n",
    "from RunningEnv import EwmaBiasState\n",
    "from TransitionBatch import TransitionBatch\n",
    "import torch as th\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_folder_path = \"~/Documents/THESIS/Project_Juan/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runner 1 - Pref.pace R: -1389\n",
      "Runner 1 - 10% faster R: -705\n",
      "Runner 2 - Pref.pace R: 444\n",
      "Runner 2 - 10% faster R: -20231\n",
      "Runner 3 - Pref.pace R: 3329\n",
      "Runner 3 - 10% faster R: 547\n",
      "Runner 4 - Pref.pace R: 3965\n",
      "Runner 4 - 10% faster R: 475\n",
      "Runner 5 - Pref.pace R: -732\n",
      "Runner 5 - 10% faster R: 3180\n",
      "Runner 6 - Pref.pace R: -215\n",
      "Runner 6 - 10% faster R: 2812\n",
      "Runner 7 - Pref.pace R: 2263\n",
      "Runner 7 - 10% faster R: -2609\n",
      "Runner 8 - Pref.pace R: -8292\n",
      "Runner 8 - 10% faster R: 2395\n",
      "Runner 9 - Pref.pace R: 703\n",
      "Runner 9 - 10% faster R: 2747\n",
      "Runner 10 - Pref.pace R: 3490\n",
      "Runner 10 - 10% faster R: 3202\n",
      "Runner 11 - Pref.pace R: 508\n",
      "Runner 11 - 10% faster R: 1041\n",
      "Runner 12 - Pref.pace R: 3552\n",
      "Runner 12 - 10% faster R: -22916\n",
      "Runner 13 - Pref.pace R: 4055\n",
      "Runner 13 - 10% faster R: -924\n",
      "Runner 14 - Pref.pace R: -2979\n",
      "Runner 14 - 10% faster R: -2492\n",
      "Runner 15 - Pref.pace R: 3116\n",
      "Runner 15 - 10% faster R: 2011\n"
     ]
    }
   ],
   "source": [
    "tests = ['PNPpref', 'PNPfast']\n",
    "test_name = ['Pref.pace', '10% faster']\n",
    "for participant in range(1, 16, 1): #16\n",
    "    participant_number = str(participant)\n",
    "\n",
    "    for i in range(len(tests)):\n",
    "        # print(\"Runner %s - %s\" % (participant_number, test_name[i]))\n",
    "        calculated_values = pd.read_csv(data_folder_path + ('calculated_variables/%s_R_%s_calculated.csv')%(tests[i], participant_number))\n",
    "\n",
    "        target_pace = calculated_values[calculated_values['pacing_frequency'].notna()]['pacing_frequency'].mean()\n",
    "        calculated_values_norm = calculated_values.copy()\n",
    "        calculated_values_norm['norm_step_frequency'] = calculated_values_norm['step_frequency']/target_pace\n",
    "\n",
    "        env = RunningEnv(target_pace)\n",
    "        wrapper = EnvWrapper(target_pace, target_pace)\n",
    "        state_func = EwmaBiasState()\n",
    "        timestep = 0\n",
    "        state = 0\n",
    "        action = 0\n",
    "        reward = 0\n",
    "        n_state = 0\n",
    "        finish_leap = False\n",
    "        skip_steps = 0\n",
    "        total_reward = 0\n",
    "        # Add first value\n",
    "        add_zero = 1\n",
    "\n",
    "        for row in calculated_values_norm.to_numpy():\n",
    "\n",
    "            if skip_steps > 0:\n",
    "                if skip_steps ==1:\n",
    "                    finish_leap = True\n",
    "                skip_steps -= 1\n",
    "                timestep += 1\n",
    "                continue\n",
    "            else:\n",
    "                avg_pace = state_func.get_next_state(row[2])\n",
    "                n_state = (avg_pace / target_pace) - 1\n",
    "\n",
    "                if timestep == 0:\n",
    "                    state = n_state\n",
    "                    timestep += 1\n",
    "                    continue\n",
    "\n",
    "                if finish_leap:\n",
    "                    # print(timestep, state, n_state, action, reward, avg_pace, target_pace)\n",
    "                    total_reward += reward\n",
    "                    # Add random small 0's\n",
    "                    add_zero = np.random.randint(0,4)\n",
    "\n",
    "                    finish_leap = False\n",
    "\n",
    "                if(not pd.isna(row[3]) and add_zero == 0):\n",
    "                    action = np.random.randint(1,len(wrapper.times))\n",
    "                    reward = - wrapper.times[action]\n",
    "                    skip_steps = wrapper.times[action] + 1\n",
    "                else:\n",
    "                    if add_zero > 0:\n",
    "                        add_zero -= 1\n",
    "                    action = 0\n",
    "                    reward = env.get_distance_reward(target_pace, avg_pace)\n",
    "                    # print(timestep, state, n_state, action, reward, avg_pace, target_pace)\n",
    "                    total_reward += reward\n",
    "\n",
    "            state = n_state\n",
    "            timestep += 1\n",
    "        print(\"Runner %s - %s R: %d\" % (participant_number, test_name[i], total_reward))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4451\n",
      "4404\n",
      "4507\n",
      "4430\n",
      "4505\n",
      "4301\n",
      "4372\n",
      "4491\n",
      "4438\n",
      "4482\n"
     ]
    }
   ],
   "source": [
    "results =np.zeros((40,10))\n",
    "tests = ['CP103', 'IP103', 'CP110', 'IP110']\n",
    "test_name = ['Continuous 3%', 'Intermittent 3%', 'Continuous 10%', 'Intermittent 10%']\n",
    "for j in range(0,10):\n",
    "    transitions = 0\n",
    "    for participant in range(1, 10, 1): #16\n",
    "        participant_number = str(participant)\n",
    "\n",
    "        for i in range(len(tests)):\n",
    "            # print(\"Runner %s - %s\" % (participant_number, test_name[i]))\n",
    "            calculated_values = pd.read_csv(data_folder_path + ('calculated_variables/%s_R_%s_calculated.csv')%(tests[i], participant_number))\n",
    "\n",
    "            target_pace = calculated_values[calculated_values['pacing_frequency'].notna()]['pacing_frequency'].mean()\n",
    "            calculated_values_norm = calculated_values.copy()\n",
    "            calculated_values_norm['norm_step_frequency'] = calculated_values_norm['step_frequency']/target_pace\n",
    "\n",
    "            env = RunningEnv(target_pace)\n",
    "            wrapper = EnvWrapper(target_pace, target_pace)\n",
    "            state_func = EwmaBiasState()\n",
    "            timestep = 0\n",
    "            state = 0\n",
    "            action = 0\n",
    "            reward = 0\n",
    "            n_state = 0\n",
    "            finish_leap = False\n",
    "            skip_steps = 0\n",
    "            total_reward = 0\n",
    "            # Add first value\n",
    "            add_zero = 1\n",
    "\n",
    "            for row in calculated_values_norm.to_numpy():\n",
    "\n",
    "                if skip_steps > 0:\n",
    "                    if skip_steps ==1:\n",
    "                        finish_leap = True\n",
    "                    skip_steps -= 1\n",
    "                    timestep += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    avg_pace = state_func.get_next_state(row[2])\n",
    "                    n_state = (avg_pace / target_pace) - 1\n",
    "\n",
    "                    if timestep == 0:\n",
    "                        state = n_state\n",
    "                        timestep += 1\n",
    "                        continue\n",
    "\n",
    "                    if finish_leap:\n",
    "                        # print(timestep, state, n_state, action, reward, avg_pace, target_pace)\n",
    "                        transitions += 1\n",
    "                        total_reward += reward\n",
    "                        # Add random small 0's\n",
    "                        add_zero = np.random.randint(0,4)\n",
    "\n",
    "                        finish_leap = False\n",
    "\n",
    "                    if(not pd.isna(row[3]) and add_zero == 0):\n",
    "                        action = np.random.randint(1,len(wrapper.times))\n",
    "                        reward = - wrapper.times[action]\n",
    "                        skip_steps = wrapper.times[action] + 1\n",
    "                    else:\n",
    "                        if add_zero > 0:\n",
    "                            add_zero -= 1\n",
    "                        action = 0\n",
    "                        reward = env.get_distance_reward(target_pace, avg_pace)\n",
    "                        # print(timestep, state, n_state, action, reward, avg_pace, target_pace)\n",
    "                        transitions += 1\n",
    "                        total_reward += reward\n",
    "\n",
    "                state = n_state\n",
    "                timestep += 1\n",
    "            # print(\"Runner %s - %s R: %d\" % (participant_number, test_name[i], total_reward))\n",
    "    print(transitions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "stats = np.concatenate((np.mean(results, axis=-1).reshape(40,1), np.std(results, axis=-1).reshape(40,1)), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "state_shape = (1,)\n",
    "def transition_format():\n",
    "    \"\"\" Returns the format of transtions: a dictionary of (shape, dtype) entries for each key. \"\"\"\n",
    "    return {'actions': ((1,), th.long),\n",
    "            'states': (state_shape, th.float32),\n",
    "            'next_states': (state_shape, th.float32),\n",
    "            'rewards': ((1,), th.float32),\n",
    "            'dones': ((1,), th.bool),\n",
    "            'returns': ((1,), th.float32)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def _wrap_transition(s, a, r, ns, d):\n",
    "    \"\"\" Takes a transition and returns a corresponding dictionary. \"\"\"\n",
    "    trans = {}\n",
    "    form = transition_format()\n",
    "    for key, val in [('states', s), ('actions', a), ('rewards', r), ('next_states', ns), ('dones', d)]:\n",
    "        if not isinstance(val, th.Tensor):\n",
    "            if isinstance(val, numbers.Number) or isinstance(val, bool): val = [val]\n",
    "            val = th.tensor(val, dtype=form[key][1])\n",
    "        if len(val.shape) < len(form[key][0]) + 1: val = val.unsqueeze(dim=0)\n",
    "        trans[key] = val\n",
    "    return trans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "my_transition_buffer = TransitionBatch(4500, transition_format())\n",
    "time, episode_start, episode_lengths, episode_rewards = 0, 0, [], []\n",
    "max_steps = 1000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runner 1 - Pref.pace R: -827\n",
      "Runner 1 - 10% faster R: -775\n",
      "Runner 2 - Pref.pace R: 64\n",
      "Runner 2 - 10% faster R: -20851\n",
      "Runner 3 - Pref.pace R: 3487\n",
      "Runner 3 - 10% faster R: 623\n",
      "Runner 4 - Pref.pace R: 3975\n",
      "Runner 4 - 10% faster R: -215\n",
      "Runner 5 - Pref.pace R: -851\n",
      "Runner 5 - 10% faster R: 2362\n",
      "Runner 6 - Pref.pace R: -215\n",
      "Runner 6 - 10% faster R: 2470\n",
      "Runner 7 - Pref.pace R: 2073\n",
      "Runner 7 - 10% faster R: -1981\n",
      "Runner 8 - Pref.pace R: -8213\n",
      "Runner 8 - 10% faster R: 1555\n",
      "Runner 9 - Pref.pace R: 553\n",
      "Runner 9 - 10% faster R: 2312\n",
      "Runner 10 - Pref.pace R: 2860\n",
      "Runner 10 - 10% faster R: 3204\n",
      "Runner 11 - Pref.pace R: -126\n",
      "Runner 11 - 10% faster R: 1370\n",
      "Runner 12 - Pref.pace R: 3422\n",
      "Runner 12 - 10% faster R: -22175\n",
      "Runner 13 - Pref.pace R: 3835\n",
      "Runner 13 - 10% faster R: -874\n",
      "Runner 14 - Pref.pace R: -2114\n",
      "Runner 14 - 10% faster R: -2465\n",
      "Runner 15 - Pref.pace R: 3202\n",
      "Runner 15 - 10% faster R: 1586\n",
      "Runner 1 - Continuous 3% R: -199\n",
      "Runner 1 - Intermittent 3% R: 2525\n",
      "Runner 1 - Continuous 10% R: -461\n",
      "Runner 1 - Intermittent 10% R: 2530\n",
      "Runner 2 - Continuous 3% R: -82\n",
      "Runner 2 - Intermittent 3% R: 2054\n",
      "Runner 2 - Continuous 10% R: -371\n",
      "Runner 2 - Intermittent 10% R: 2747\n",
      "Runner 3 - Continuous 3% R: 285\n",
      "Runner 3 - Intermittent 3% R: 165\n",
      "Runner 3 - Continuous 10% R: -245\n",
      "Runner 3 - Intermittent 10% R: 2667\n",
      "Runner 4 - Continuous 3% R: 225\n",
      "Runner 4 - Intermittent 3% R: 2435\n",
      "Runner 4 - Continuous 10% R: -491\n",
      "Runner 4 - Intermittent 10% R: 1732\n",
      "Runner 5 - Continuous 3% R: 90\n",
      "Runner 5 - Intermittent 3% R: 1641\n",
      "Runner 5 - Continuous 10% R: -205\n",
      "Runner 5 - Intermittent 10% R: 1804\n",
      "Runner 6 - Continuous 3% R: 80\n",
      "Runner 6 - Intermittent 3% R: 880\n",
      "Runner 6 - Continuous 10% R: -801\n",
      "Runner 6 - Intermittent 10% R: 1884\n",
      "Runner 7 - Continuous 3% R: -360\n",
      "Runner 7 - Intermittent 3% R: 2780\n",
      "Runner 7 - Continuous 10% R: -7\n",
      "Runner 7 - Intermittent 10% R: 2480\n",
      "Runner 8 - Continuous 3% R: 175\n",
      "Runner 8 - Intermittent 3% R: 1414\n",
      "Runner 8 - Continuous 10% R: -586\n",
      "Runner 8 - Intermittent 10% R: 1978\n",
      "Runner 9 - Continuous 3% R: -441\n",
      "Runner 9 - Intermittent 3% R: 1280\n",
      "Runner 9 - Continuous 10% R: -549\n",
      "Runner 9 - Intermittent 10% R: -14480\n"
     ]
    }
   ],
   "source": [
    "exp_batch = [16, 10]\n",
    "t = 0\n",
    "gamma = 0.99\n",
    "tests = [['PNPpref', 'PNPfast'], ['CP103', 'IP103', 'CP110', 'IP110']]\n",
    "test_name = [['Pref.pace', '10% faster'], ['Continuous 3%', 'Intermittent 3%', 'Continuous 10%', 'Intermittent 10%']]\n",
    "\n",
    "for exp in range(len(exp_batch)):\n",
    "    for participant in range(1, exp_batch[exp]):\n",
    "        participant_number = str(participant)\n",
    "        for i in range(len(tests[exp])):\n",
    "            calculated_values = pd.read_csv(data_folder_path + ('calculated_variables/%s_R_%s_calculated.csv')%(tests[exp][i], participant_number))\n",
    "\n",
    "            target_pace = calculated_values[calculated_values['pacing_frequency'].notna()]['pacing_frequency'].mean()\n",
    "            calculated_values_norm = calculated_values.copy()\n",
    "            calculated_values_norm['norm_step_frequency'] = calculated_values_norm['step_frequency']/target_pace\n",
    "\n",
    "            env = RunningEnv(target_pace)\n",
    "            wrapper = EnvWrapper(target_pace, target_pace)\n",
    "            state_func = EwmaBiasState()\n",
    "            timestep = 0\n",
    "            state = 0\n",
    "            action = 0\n",
    "            reward = 0\n",
    "            n_state = 0\n",
    "            finish_leap = False\n",
    "            skip_steps = 0\n",
    "            total_reward = 0\n",
    "            # Add first value\n",
    "            add_zero = 1\n",
    "\n",
    "            for row in calculated_values_norm.to_numpy():\n",
    "\n",
    "                if skip_steps > 0:\n",
    "                    if skip_steps ==1:\n",
    "                        finish_leap = True\n",
    "                    skip_steps -= 1\n",
    "                    timestep += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    avg_pace = state_func.get_next_state(row[2])\n",
    "                    n_state = (avg_pace / target_pace) - 1\n",
    "\n",
    "                    if timestep == 0:\n",
    "                        state = n_state\n",
    "                        timestep += 1\n",
    "                        continue\n",
    "\n",
    "                    if finish_leap:\n",
    "                        # print(timestep, state, n_state, action, reward, avg_pace, target_pace)\n",
    "                        my_transition_buffer.add(_wrap_transition(state, action, reward, n_state, 0))\n",
    "                        t+=1\n",
    "                        total_reward += reward\n",
    "                        # Add random small 0's\n",
    "                        # add_zero = np.random.randint(0,4)\n",
    "\n",
    "                        finish_leap = False\n",
    "\n",
    "                    if(not pd.isna(row[3]) and add_zero == 0):\n",
    "                        action = np.random.randint(1,len(wrapper.times))\n",
    "                        reward = - wrapper.times[action]\n",
    "                        skip_steps = wrapper.times[action] + 1\n",
    "                    else:\n",
    "                        if add_zero > 0:\n",
    "                            add_zero -= 1\n",
    "                        action = 0\n",
    "                        reward = env.get_distance_reward(target_pace, avg_pace)\n",
    "                        # print(timestep, state, n_state, action, reward, avg_pace, target_pace)\n",
    "                        my_transition_buffer.add(_wrap_transition(state, action, reward, n_state, 0))\n",
    "                        t+=1\n",
    "                        total_reward += reward\n",
    "\n",
    "                state = n_state\n",
    "                timestep += 1\n",
    "            # results[((participant-1)*4)+(i)][j] = total_reward\n",
    "            if t > 4500:\n",
    "                t=4500-1\n",
    "            my_transition_buffer['returns'][t] = my_transition_buffer['rewards'][t]\n",
    "            for i2 in range(t - 1, episode_start - 1, -1):\n",
    "                my_transition_buffer['returns'][i2] = my_transition_buffer['rewards'][i2] \\\n",
    "                                                     + gamma * my_transition_buffer['returns'][i2 + 1]\n",
    "            episode_start = t + 1\n",
    "            print(\"Runner %s - %s R: %d\" % (participant_number, test_name[exp][i], total_reward))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "sample = my_transition_buffer.sample()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}