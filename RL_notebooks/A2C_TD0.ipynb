{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "prediction = model(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward() # backward pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "optim.step() #gradient descent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([2., 2.])\n",
    "Q.sum().backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36., 81.])\n",
      "tensor([-12.,  -8.])\n",
      "tensor([36., 81.], grad_fn=<MulBackward0>) tensor([-12.,  -8.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)\n",
    "print(b.grad)\n",
    "print(9*a**2, -2*b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 tensor(1., grad_fn=<MulBackward0>)\n",
      "tensor([[2., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "0 1 tensor(4., grad_fn=<MulBackward0>)\n",
      "tensor([[2., 4., 0.],\n",
      "        [0., 0., 0.]])\n",
      "0 2 tensor(9., grad_fn=<MulBackward0>)\n",
      "tensor([[2., 4., 6.],\n",
      "        [0., 0., 0.]])\n",
      "1 0 tensor(16., grad_fn=<MulBackward0>)\n",
      "tensor([[2., 4., 6.],\n",
      "        [8., 0., 0.]])\n",
      "1 1 tensor(25., grad_fn=<MulBackward0>)\n",
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10.,  0.]])\n",
      "1 2 tensor(36., grad_fn=<MulBackward0>)\n",
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n",
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float, requires_grad=True)\n",
    "for i in range(2):\n",
    "  for j in range(3):\n",
    "    out = a[i,j] * a[i,j]\n",
    "    print(i, j, out)\n",
    "    out.backward()\n",
    "    print(a.grad)\n",
    "print(a.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import gym\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#discount factor for future utilities\n",
    "DISCOUNT_FACTOR = 0.99\n",
    "\n",
    "#number of episodes to run\n",
    "NUM_EPISODES = 1000\n",
    "\n",
    "#max steps per episode\n",
    "MAX_STEPS = 5000\n",
    "\n",
    "#device to run model on\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "#Using a neural network to learn our policy parameters\n",
    "class PolicyNetwork(nn.Module):\n",
    "\n",
    "    #Takes in observations and outputs actions\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.input_layer = nn.Linear(observation_space, 128)\n",
    "        self.output_layer = nn.Linear(128, action_space)\n",
    "\n",
    "    #forward pass\n",
    "    def forward(self, x):\n",
    "        #input states\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        #relu activation\n",
    "        x = F.relu(x)\n",
    "\n",
    "        #actions\n",
    "        actions = self.output_layer(x)\n",
    "\n",
    "        #get softmax for a probability distribution\n",
    "        action_probs = F.softmax(actions, dim=1)\n",
    "\n",
    "        return action_probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def action_from_uniform_dist(action_space):\n",
    "    ''' Select an action from a uniform distribution\n",
    "    Args:\n",
    "    - action_space (int): Number of actions in the action space of environment\n",
    "\n",
    "    Return:\n",
    "    - (int): Action sampled from uniform distribution\n",
    "    - (int): Probability of action being sampled\n",
    "\n",
    "    '''\n",
    "\n",
    "    #uniform distribution of all actions in environment\n",
    "    dist = torch.Tensor(np.full(action_space, 1/action_space)).to(DEVICE)\n",
    "\n",
    "    #sample action\n",
    "    m = Categorical(dist)\n",
    "    action = m.sample()\n",
    "\n",
    "    #return action and probability\n",
    "    return action.item(), dist[action.item()].item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}